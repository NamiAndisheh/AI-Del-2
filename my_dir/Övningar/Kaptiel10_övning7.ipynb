{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9472a6",
   "metadata": {},
   "source": [
    "# Chattbottar övning 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a3bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google import genai\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0b057",
   "metadata": {},
   "source": [
    "# 1. Anropar API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103f9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zlatan Ibrahimović är en svensk före detta professionell fotbollsspelare som spelade som anfallare. Han anses vara en av de bästa anfallarna genom tiderna och är den bästa målskytten i Sveriges landslag.\n",
      "\n",
      "Här är en kort sammanfattning av hans karriär:\n",
      "\n",
      "*   **Före detta klubbar:** Malmö FF, Ajax, Juventus, Inter Milan, Barcelona, AC Milan, Paris Saint-Germain (PSG), Manchester United, LA Galaxy och AC Milan (igen).\n",
      "*   **Landslag:** Spelade för Sverige i många år och är landslagets bästa målskytt genom tiderna.\n",
      "*   **Kännetecken:** Känd för sin otroliga teknik, styrka, akrobatiska mål och starka personlighet.\n",
      "*   **Meriter:** Har vunnit ligatitlar i Nederländerna, Italien, Frankrike och England. Han har även vunnit många individuella priser.\n",
      "*   **Pension:** Han meddelade att han slutar sin professionella karriär i juni 2023.\n",
      "\n",
      "Han är en mycket populär och omtalad person, inte bara för sina fotbollskunskaper utan också för sin karismatiska och självsäkra personlighet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "api_key = api_key=os.getenv(\"API_KEY\")\n",
    "\n",
    "api_key = 'AIzaSyAZ_7tz9oaIOkn0Nd-jFVii6OuXhqPhQxk'\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    contents=\"vem är zlatan\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c03d29",
   "metadata": {},
   "source": [
    "# 2. Gör så att jag kan snacka genom terminalen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeec226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Gemini chat ***\n",
      "Type <q> to exit chat.\n",
      "Gemini: Hej! Hur kan jag hjälpa dig idag?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Gemini chat ***\")\n",
    "print(\"Type <q> to exit chat.\")\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"User: \")\n",
    "    if prompt == \"q\":\n",
    "        break\n",
    "    else:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        print(\"Gemini:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1cf207",
   "metadata": {},
   "source": [
    "# 3. Hämtar PDF filen så den kan läsa igenom texten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf37055",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"../../chattbot.pdf\")\n",
    "\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145bb69",
   "metadata": {},
   "source": [
    "# 4. Här kan jag hämta vilket stycke i texten den ska visa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea6d04e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    }
   ],
   "source": [
    "print(text[27:28])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8316851",
   "metadata": {},
   "source": [
    "# 5. Gör en chunk metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2773343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal chunks: 30.\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "n = 1000\n",
    "overlap = 200\n",
    "for i in range(0, len(text), n - overlap):\n",
    "    chunks.append(text[i:i + n])\n",
    "\n",
    "print(f\"Antal chunks: {len(chunks)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c6586",
   "metadata": {},
   "source": [
    "# 6. Embeddings (omvandlar text till siffror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb35f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "def create_embeddings(text, model=\"text-embedding-004\", task_type=\"SEMANTIC_SIMILARITY\"): \n",
    "    return client.models.embed_content(model=model, contents=text, config=types.EmbedContentConfig(task_type=task_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b42efa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = create_embeddings(chunks)\n",
    "len(embeddings.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80ced58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.07625509,\n",
       " -0.001474135,\n",
       " -0.04945821,\n",
       " 0.018019233,\n",
       " 0.03574536,\n",
       " 0.005913627,\n",
       " 0.038222753,\n",
       " 0.00028628064,\n",
       " 0.0069102156,\n",
       " -0.056053966]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embeddings)\n",
    "\n",
    "embeddings.embeddings[5].values[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698042d",
   "metadata": {},
   "source": [
    "# 7. Semantisk sökning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9909cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return (np.dot(vec1, vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81f615d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, chunks, embeddings, k=5):\n",
    "    query_embedding = create_embeddings(query).embeddings[0].values \n",
    "    similarity_scores = []\n",
    "    \n",
    "    for i, chunk_embedding in enumerate(embeddings.embeddings):\n",
    "        similarity_score = cosine_similarity(query_embedding, chunk_embedding.values)\n",
    "        similarity_scores.append((i, similarity_score))\n",
    "\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [index for index, _ in similarity_scores[:k]]\n",
    "    \n",
    "    return [chunks[index] for index in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2d0b098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i ger\\nmodellen en kontext, ofta ett eller flera dokument eller liknande, att förhålla sig till.\\nI en prompt säger vi åt modellen att enbart svara utifrån den givna kontexten. Om\\nmodellen inte hittar svaret i kontexten ska den säga det istället för att försöka hitta\\nsvaren någon annanstans eller gissa.\\n7En RAG-modell innehåller alltså två delar.\\nDen första delen är en retriever, som söker efter relevanta stycken i en större text.\\nDessa stycken skickas sedan vidare som kontext till den andra delen, en generator som\\ngenererar svaren utifrån den givna kontexten.\\nFör att ge modellen en kontext behöver vi läsa in data (exempelvis ett eller flera PDF-\\ndokument) och bearbeta den så att vi kan göra en semantisk sökning i datan, det vill\\nsäga leta upp de stycken i kontexten som verkar ha mest med själva frågan att göra.\\nDessa stycken skickar vi sedan med till språkmodellen när vi ställer vår fråga.\\nDet finns ett antal ramverk för att implementera RAG, bland annat LangChain. Vi\\nkommer inte använd']\n"
     ]
    }
   ],
   "source": [
    "fråga = \"Vad kan RAG användas till?\"\n",
    "svar = semantic_search(fråga, chunks=chunks, embeddings=embeddings, k=1)\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e607d1",
   "metadata": {},
   "source": [
    "# 8. Generera bra svar med RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbc3bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Jag kommer ställa dig en fråga, och jag vill att du svarar\n",
    "baserat bara på kontexten jag skickar med, och ingen annan information.\n",
    "Om det inte finns nog med information i kontexten för att svara på frågan,\n",
    "säg \"Det vet jag inte\". Försök inte att gissa.\n",
    "Formulera dig enkelt och dela upp svaret i fina stycken. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc0f1642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt(query):\n",
    "    context = \"\\n\".join(semantic_search(query, chunks, embeddings))\n",
    "    user_prompt = f\"Frågan är {query}. Här är kontexten: {context}.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "869a84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(system_prompt, user_message, model=\"gemini-2.0-flash\"):\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=system_prompt),\n",
    "            contents=generate_user_prompt(user_message)\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82c666a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det vet jag inte.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(system_prompt, \"Vad är fotboll?\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fba2c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering handlar om att ställa effektiva frågor till chattbottar för att få bättre svar. Det innebär att vara så specifik, deskriptiv och detaljerad som möjligt om önskad kontext, utfall, längd, format och stil.\n"
     ]
    }
   ],
   "source": [
    "fråga = \"Vad är prompt engineering?\"\n",
    "svar = generate_response(system_prompt, fråga).text\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab67b9",
   "metadata": {},
   "source": [
    "# 9. Evaluering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a733cd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilka delar utgör en RAG-modell?\n",
      "\n",
      "En RAG-modell innehåller två delar: \n",
      "en retriever som söker efter relevanta stycken i en text, \n",
      "och en generator som genererar svar utifrån den givna kontexten.\n"
     ]
    }
   ],
   "source": [
    "validation_data = [\n",
    "{\"question\": \"Vilka delar utgör en RAG-modell?\",\n",
    "\"ideal_answer\": \"\"\"En RAG-modell innehåller två delar: \n",
    "en retriever som söker efter relevanta stycken i en text, \n",
    "och en generator som genererar svar utifrån den givna kontexten.\"\"\"}\n",
    "]\n",
    "\n",
    "print(validation_data[0][\"question\"])\n",
    "print()\n",
    "print(validation_data[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "814be31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_system_prompt = \"\"\"Du är ett intelligent utvärderingssystem vars uppgift är att utvärdera en AI-assistents svar. \n",
    "Om svaret är väldigt nära det önskade svaret, sätt poängen 1. Om svaret är felaktigt eller inte bra nog, sätt poängen 0.\n",
    "Om svaret är delvis i linje med det önskade svaret, sätt poängen 0.5. Motivera kort varför du sätter den poäng du gör.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f98734df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poäng: 1\n",
      "Motivering: Svaret är korrekt och sammanfattar de väsentliga delarna av en RAG-modell.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "\n",
    "evaluation_prompt = f\"\"\"Fråga: {query}\n",
    "AI-assistentens svar: {response.text}\n",
    "Önskat svar: {validation_data[0]['ideal_answer']}\"\"\"\n",
    "\n",
    "# Note, we have created a \"evaluation_system_prompt\" and a \"evaluation_prompt\" that we use in our function \"generate_response\" that we created before. \n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt)\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1ef4356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilket programmeringsspråk är kapitlet skrivet i?\n",
      "Python\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_data_2 = [\n",
    "{\"question\": \"Vilket programmeringsspråk är kapitlet skrivet i?\",\n",
    "\"ideal_answer\": \"Python\"}\n",
    "]\n",
    "print(validation_data_2[0][\"question\"])\n",
    "print(validation_data_2[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8a5ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kapitlet är skrivet i programmeringsspråket Python.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = validation_data_2[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
