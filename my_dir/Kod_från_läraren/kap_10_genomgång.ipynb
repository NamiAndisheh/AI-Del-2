{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e725c060-4af6-42f1-94bb-0b02124f5941",
   "metadata": {},
   "source": [
    "# Chattbottar - Kapitel 10 \n",
    "\n",
    "I detta kodexempel ska vi få en grundläggande förståelse för hur chattbottar fungerar. Let's go! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96af92f8-2199-4037-93f2-bdef2525eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google import genai\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2555a65-c0af-4927-ac22-43cc9f58d4e9",
   "metadata": {},
   "source": [
    "# Använda en chattbott genom API\n",
    "Vi kommer nu demonstrera hur vi kan ha en egen chattbott genom att använda en API-nyckel från Google i detta fall. Andra alternativ är t.ex. ChatGPT/OpenAI. \n",
    "Om du i verkligheten ska arbeta med chattbottar kommer du mest sannolikt att använda färdiga API. \n",
    "\n",
    "För att skapa en API-nyckel behöver du gå in på följande hemsids: https://aistudio.google.com/ och sen gå till \"Create API key\". Notera, du behöver registrera ditt bankkort för att få en gratis provperiod. Annars funkar det inte. Som vanlig praxis inom systemutveckling så delar du inte din privata API-nyckel eftersom då kan andra använda den vilket kostar pengar. Man kan använda \"api_key = api_key=os.getenv(\"API_KEY\")\" för detta ändamål. I koden nedan **skriver jag explicit ut min API-nyckel som du dock inte kommer kuna använda (du behöver skapa en egen)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f1ffd-c832-4fd2-89f3-85bb958f75b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zlatan Ibrahimović är en svensk fotbollsspelare som anses vara en av de bästa anfallarna genom tiderna. Han är känd för sin teknik, styrka, akrobatik och starka personlighet.\n",
      "\n",
      "Här är några viktiga punkter om honom:\n",
      "\n",
      "*   **Född:** 3 oktober 1981 i Malmö, Sverige.\n",
      "*   **Position:** Anfallare.\n",
      "*   **Klubbar han spelat för (ett urval):** Malmö FF, Ajax, Juventus, Inter Milan, Barcelona, AC Milan, Paris Saint-Germain, Manchester United, LA Galaxy.\n",
      "*   **Landslag:** Svenska landslaget (rekordmålskytt).\n",
      "*   **Meriter:** Han har vunnit ligatitlar i fyra olika länder (Nederländerna, Italien, Frankrike och England) och har gjort över 500 mål under sin karriär.\n",
      "*   **Känd för:** Hans spektakulära mål, uttalanden och självförtroende. Han är också känd för att prata om sig själv i tredje person.\n",
      "\n",
      "Sammanfattningsvis är Zlatan Ibrahimović en legendarisk fotbollsspelare som har satt ett stort avtryck på sporten.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "api_key = api_key=os.getenv(\"API_KEY\")\n",
    "\n",
    "api_key = 'AIzaSyAZ_7tz9oaIOkn0Nd-jFVii6OuXhqPhQxk'\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    contents=\"vem är zlatan\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cdd7aa-1866-4107-a502-156f152cbfc5",
   "metadata": {},
   "source": [
    "# Skapa en mycket enkel applikation\n",
    "Vi kan också skapa en enkel applikation. Men lite kreativitet så inser man att det finns många möjligheter att bygga/utveckla sådant man är intresserad av."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5d2d8a-4373-4d58-bdff-8c2158745cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Gemini chat ***\n",
      "Type <q> to exit chat.\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Gemini chat ***\")\n",
    "print(\"Type <q> to exit chat.\")\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"User: \")\n",
    "    if prompt == \"q\":\n",
    "        break\n",
    "    else:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        print(\"Gemini:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abe017-f8a7-4244-b99f-cb0f7ddfcfc1",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ed0f7-7d1c-466a-a23d-341f17661949",
   "metadata": {},
   "source": [
    "## Läsa in PDF-fil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd0aa4-549d-4e90-b6a9-e936c185a3df",
   "metadata": {},
   "source": [
    "Vi börjar med att läsa in en PDF-fil som chattbotten kommer ge svar utifrån. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f7836c-9675-4aae-8e45-70bb7c37e7eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PdfReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../chattbot.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PdfReader' is not defined"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"../../chattbot.pdf\")\n",
    "\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc92a8d5-92b6-4b54-b03f-56ee19e358e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23416\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26511ad6-f832-465f-bb83-3d223bf86541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chattbot\n",
      "1.1 Chattbottar\n",
      "I detta kapitel kommer vi lära oss mer om hur chattbottar såsom ChatGPT fungerar och\n",
      "hur man ställer effektiva frågor till dem, vilket kallas prompt engineering . Vi kommer\n",
      "därefter lära oss hur vi bygger en lokal chattbot som vi kan använda på vår egna dator.\n",
      "Kapitlet avslutas med att gå igenom RAG vilket låter oss anpassa chattbottens svar\n",
      "utifrån en given kontext, exempelvis utifrån egna dokument.\n",
      "1.1.1 ChatGPT och prompt engineering\n",
      "Chattbottar, som till exempel ChatGPT, används av många människor \n"
     ]
    }
   ],
   "source": [
    "print(text[27:559])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd44ee3-1f37-49fd-89cd-15d8cfe53008",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea598391-db66-47e1-9906-657a2b43b920",
   "metadata": {},
   "source": [
    "### Fixed length-chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141465a2-4992-4a3d-a312-b1994623820b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtext\u001b[49m), n \u001b[38;5;241m-\u001b[39m overlap):\n\u001b[1;32m      5\u001b[0m     chunks\u001b[38;5;241m.\u001b[39mappend(text[i:i \u001b[38;5;241m+\u001b[39m n])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAntal chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "n = 1000\n",
    "overlap = 200\n",
    "for i in range(0, len(text), n - overlap):\n",
    "    chunks.append(text[i:i + n])\n",
    "\n",
    "print(f\"Antal chunks: {len(chunks)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f1d1208-8c68-48b2-a938-8d6c7f7f70da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chattbot med RAG2Kapitel 1\n",
      "Chattbot\n",
      "1.1 Chattbottar\n",
      "I detta kapitel kommer vi lära oss mer om hur chattbottar såsom ChatGPT fungerar och\n",
      "hur man ställer effektiva frågor till dem, vilket kallas prompt engineering . Vi kommer\n",
      "därefter lära oss hur vi bygger en lokal chattbot som vi kan använda på vår egna dator.\n",
      "Kapitlet avslutas med att gå igenom RAG vilket låter oss anpassa chattbottens svar\n",
      "utifrån en given kontext, exempelvis utifrån egna dokument.\n",
      "1.1.1 ChatGPT och prompt engineering\n",
      "Chattbottar, som till exempel ChatGPT, används av många människor för en rad olika\n",
      "syften. Alltifrån att skapa kreativt innehåll, få förslag på förbättringar av skriven text\n",
      "eller programmeringskod till att lösa mer komplexa problem.\n",
      "I korthet har chattbottar tränats på enorma datamängder och har från detta lärt sig vad\n",
      "som är rimliga sekvenser av ord. Exempelvis vet vi att om någon säger “Hej, hur mår\n",
      "___” så brukar det sista ordet vara “du” för att meningen ska bli “Hej, hur mår du” .\n",
      "När vi ställer \n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0268d77-6602-4457-ac6e-f7e209c02b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chattbot\n",
      "1.1 Chattbottar\n",
      "I detta kapitel kommer vi lära oss mer om hur chattbottar såsom ChatGPT fungerar och\n",
      "hur man ställer effektiva frågor till dem, vilket kallas prompt engineering . Vi kommer\n",
      "därefter lära oss hur vi bygger en lokal chattbot som vi kan använda på vår egna dator.\n",
      "Kapitlet avslutas med att gå igenom RAG vilket låter oss anpassa chattbottens svar\n",
      "utifrån en given kontext, exempelvis utifrån egna dokument.\n",
      "1.1.1 ChatGPT och prompt engineering\n",
      "Chattbottar, som till exempel ChatGPT, används av många människor för en rad olika\n",
      "syften. \n"
     ]
    }
   ],
   "source": [
    "print(text[26:584])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06000c-d0d4-45f0-a674-715a616ca36c",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "Se t.ex. s.321 i kursboken \"Lär dig AI från grunden - Tillämpad maskininlärning med Python\" för vad Embeddings innebär. I korthet, ord representeras med vektorer/siffror. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52e145a-8684-4aa6-a192-7e98b1d18ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "def create_embeddings(text, model=\"text-embedding-004\", task_type=\"SEMANTIC_SIMILARITY\"): \n",
    "    return client.models.embed_content(model=model, contents=text, config=types.EmbedContentConfig(task_type=task_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d25a867-4b3a-479a-a490-f6723bbc4ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = create_embeddings(chunks)\n",
    "len(embeddings.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b824e558-81ba-4065-83b1-60b2fe6d683f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.057309315,\n",
       " -0.010547505,\n",
       " -0.08322796,\n",
       " 0.024299115,\n",
       " 0.055630915,\n",
       " 0.048652556,\n",
       " 0.049652215,\n",
       " -0.027345037,\n",
       " 0.044459436,\n",
       " -0.042770572]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embeddings)\n",
    "\n",
    "embeddings.embeddings[0].values[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414a050-0e5f-4d51-8322-fe8e225aca50",
   "metadata": {},
   "source": [
    "## Semantisk sökning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e252a24b-c86b-4152-8045-7b7dc5a692ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return (np.dot(vec1, vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f99cc00-f005-41dc-9df8-cd0054734a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, chunks, embeddings, k=5):\n",
    "    query_embedding = create_embeddings(query).embeddings[0].values \n",
    "    similarity_scores = []\n",
    "    \n",
    "    for i, chunk_embedding in enumerate(embeddings.embeddings):\n",
    "        similarity_score = cosine_similarity(query_embedding, chunk_embedding.values)\n",
    "        similarity_scores.append((i, similarity_score))\n",
    "\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [index for index, _ in similarity_scores[:k]]\n",
    "    \n",
    "    return [chunks[index] for index in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bbb0be9-e15c-46de-9c2d-3b32c94e392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i ger\\nmodellen en kontext, ofta ett eller flera dokument eller liknande, att förhålla sig till.\\nI en prompt säger vi åt modellen att enbart svara utifrån den givna kontexten. Om\\nmodellen inte hittar svaret i kontexten ska den säga det istället för att försöka hitta\\nsvaren någon annanstans eller gissa.\\n7En RAG-modell innehåller alltså två delar.\\nDen första delen är en retriever, som söker efter relevanta stycken i en större text.\\nDessa stycken skickas sedan vidare som kontext till den andra delen, en generator som\\ngenererar svaren utifrån den givna kontexten.\\nFör att ge modellen en kontext behöver vi läsa in data (exempelvis ett eller flera PDF-\\ndokument) och bearbeta den så att vi kan göra en semantisk sökning i datan, det vill\\nsäga leta upp de stycken i kontexten som verkar ha mest med själva frågan att göra.\\nDessa stycken skickar vi sedan med till språkmodellen när vi ställer vår fråga.\\nDet finns ett antal ramverk för att implementera RAG, bland annat LangChain. Vi\\nkommer inte använd']\n"
     ]
    }
   ],
   "source": [
    "fråga = \"Vad kan RAG användas till?\"\n",
    "svar = semantic_search(fråga, chunks=chunks, embeddings=embeddings, k=1)\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c860ec-2f8c-4a51-8472-f1726ad57ccf",
   "metadata": {},
   "source": [
    "## Generera bra svar med RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7073be44-fe23-4420-a339-7e42a1781d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Jag kommer ställa dig en fråga, och jag vill att du svarar\n",
    "baserat bara på kontexten jag skickar med, och ingen annan information.\n",
    "Om det inte finns nog med information i kontexten för att svara på frågan,\n",
    "säg \"Det vet jag inte\". Försök inte att gissa.\n",
    "Formulera dig enkelt och dela upp svaret i fina stycken. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f5699b1-5a6c-4811-a0ec-dd1ab5342f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt(query):\n",
    "    context = \"\\n\".join(semantic_search(query, chunks, embeddings))\n",
    "    user_prompt = f\"Frågan är {query}. Här är kontexten: {context}.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a7b5a6-d8e8-4692-87c7-fd49fac36061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(system_prompt, user_message, model=\"gemini-2.0-flash\"):\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=system_prompt),\n",
    "            contents=generate_user_prompt(user_message)\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166eed64-fbef-4d57-adad-8df1cccab7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "555d729f-44bb-4e62-8949-5344c72c44b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'semantic_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVad är RAG?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext)\n",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(system_prompt, user_message, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_response\u001b[39m(system_prompt, user_message, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.0-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m      3\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m         config\u001b[38;5;241m=\u001b[39mgenai\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mGenerateContentConfig(\n\u001b[1;32m      5\u001b[0m             system_instruction\u001b[38;5;241m=\u001b[39msystem_prompt),\n\u001b[0;32m----> 6\u001b[0m             contents\u001b[38;5;241m=\u001b[39m\u001b[43mgenerate_user_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m         )\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36mgenerate_user_prompt\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_user_prompt\u001b[39m(query):\n\u001b[0;32m----> 2\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43msemantic_search\u001b[49m(query, chunks, embeddings))\n\u001b[1;32m      3\u001b[0m     user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrågan är \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Här är kontexten: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_prompt\n",
      "\u001b[0;31mNameError\u001b[0m: name 'semantic_search' is not defined"
     ]
    }
   ],
   "source": [
    "print(generate_response(system_prompt, \"Vad är RAG?\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9c38332-cd4a-4838-8270-b1253d05046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det vet jag inte.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fråga = \"Vad är meningen med livet?\"\n",
    "svar = generate_response(system_prompt, fråga).text\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c5485b9-44d8-4639-9215-eb60393a0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering handlar om att ställa effektiva frågor till chattbottar för att få bättre svar. Det innebär att man är så specifik, deskriptiv och detaljerad som möjligt om önskad kontext, utfall, längd, format och stil.\n"
     ]
    }
   ],
   "source": [
    "fråga = \"Vad är prompt engineering?\"\n",
    "svar = generate_response(system_prompt, fråga).text\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f643f7-92d1-49b2-bb5a-546098474dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8aaf2a8-418f-45e8-9c6b-5d43ee71b53c",
   "metadata": {},
   "source": [
    "# Evaluering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cffc8c93-efc5-4ffe-9239-2f98dd210aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilka delar utgör en RAG-modell?\n",
      "\n",
      "En RAG-modell innehåller två delar: \n",
      "en retriever som söker efter relevanta stycken i en text, \n",
      "och en generator som genererar svar utifrån den givna kontexten.\n"
     ]
    }
   ],
   "source": [
    "validation_data = [\n",
    "{\"question\": \"Vilka delar utgör en RAG-modell?\",\n",
    "\"ideal_answer\": \"\"\"En RAG-modell innehåller två delar: \n",
    "en retriever som söker efter relevanta stycken i en text, \n",
    "och en generator som genererar svar utifrån den givna kontexten.\"\"\"}\n",
    "]\n",
    "\n",
    "print(validation_data[0][\"question\"])\n",
    "print()\n",
    "print(validation_data[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280210b-11c3-4420-8641-652343e25ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9443d6e1-dc9f-41b2-924e-f28a2226bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_system_prompt = \"\"\"Du är ett intelligent utvärderingssystem vars uppgift är att utvärdera en AI-assistents svar. \n",
    "Om svaret är väldigt nära det önskade svaret, sätt poängen 1. Om svaret är felaktigt eller inte bra nog, sätt poängen 0.\n",
    "Om svaret är delvis i linje med det önskade svaret, sätt poängen 0.5. Motivera kort varför du sätter den poäng du gör.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55e42632-b16f-477a-a84a-e8b4816a4d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poäng: 1\n",
      "\n",
      "Motivering: Svaret är korrekt och i linje med det önskade svaret.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "\n",
    "evaluation_prompt = f\"\"\"Fråga: {query}\n",
    "AI-assistentens svar: {response.text}\n",
    "Önskat svar: {validation_data[0]['ideal_answer']}\"\"\"\n",
    "\n",
    "# Note, we have created a \"evaluation_system_prompt\" and a \"evaluation_prompt\" that we use in our function \"generate_response\" that we created before. \n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt)\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4392962-0b5f-4b60-a5ed-18a30cf93b09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c826583-997a-4c5b-8b8f-233e2f123994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilket programmeringsspråk är kapitlet skrivet i?\n",
      "Python\n"
     ]
    }
   ],
   "source": [
    "# Try change to \"ideal_answer\": \"Java\" and notice that if the user defines the wrong \"ideal answer\", then it gets weird. \n",
    "# In a wider context, how do you define ideal answers to questions that have no exact answer and who does this? \n",
    "\n",
    "validation_data_2 = [\n",
    "{\"question\": \"Vilket programmeringsspråk är kapitlet skrivet i?\",\n",
    "\"ideal_answer\": \"Python\"}\n",
    "]\n",
    "print(validation_data_2[0][\"question\"])\n",
    "print(validation_data_2[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4d6055f-2009-46e2-8039-d94e71eb3747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kapitlet är skrivet i programmeringsspråket Python.\n",
      "*   Detta indikeras av kodexempel som:\n",
      "\n",
      "    ```python\n",
      "    from pypdf import PdfRead\n",
      "    ```\n",
      "*   Användningen av Python-bibliotek som `pypdf` och `numpy` nämns också.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data_2[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9d8c553-7230-4456-baef-2ef2255df433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poäng: 1\n",
      "\n",
      "Motivering: Svaret är korrekt och välmotiverat utifrån den givna kontexten.\n"
     ]
    }
   ],
   "source": [
    "evaluation_prompt = f\"\"\"Fråga: {query}\n",
    "AI-assistentens svar: {response.text}\n",
    "Önskat svar: {validation_data_2[0]['ideal_answer']}\"\"\"\n",
    "\n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt)\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62463f-4ae4-4ad0-acc8-ce11f85a4ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5086c60a-10bc-47cc-8754-4c548cb864c4",
   "metadata": {},
   "source": [
    "# Fördjupning\n",
    "Den som är intresserad av att arbeta med chattbottar för t.ex. del 2 av kunskapskontrollen kan fördjupa sig inom LangChain, se t.ex. här: \n",
    "https://academy.langchain.com/collections/foundation\n",
    "\n",
    "Vill man få en snabb överblick, se t.ex. \"Quickstart LangChain Essentials - Python\" här: https://academy.langchain.com/collections/quickstart\n",
    "\n",
    "Vill man få en överblick över LangChain, LangGraph och LangSmith, se här: https://www.youtube.com/watch?v=vJOGC8QJZJQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64949f44-e5b7-4424-93f2-b799b14237f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
